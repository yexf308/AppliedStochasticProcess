{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5Jy78dG9qXBNlGCfPW9R/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStochasticProcess/blob/main/HW/HW2/560Sp23HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gHX-L_CuLyy"
      },
      "outputs": [],
      "source": [
        "%pylab inline \n",
        "import numpy.linalg as LA\n",
        "import codecs, json\n",
        "from time import time\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import io\n",
        "from random import random\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import dropwhile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n",
        "# Homework 2\n",
        "## Homework guideline\n",
        "- The deadline is Mar 10th 10:30am. Submission after the deadline will not be graded. \n",
        "\n",
        "- Submit your work(your reasoning and your code) as a SINGLE .ipynb document. Please rename the document as _HW1_YOURNAME.ipynb_ (for example, _HW1_FELIX.ipynb_). You are responsible for checking that you have correctly submitted the correct document. If your code cannot run, you may receive NO point. \n",
        "\n",
        "- Please justify all short answers with a brief explanation. If you use latex command in the markdown, **2 points** bonus will be awarded.   \n",
        "\n",
        "- You only use the Python packages included in the following cell. You are not allowed to use other advanced package or modules unless you are permitted to. \n",
        "\n",
        "- In your final submission include the plots produced by the unedited code as presented below, as well as any additional plots produced after editing the code during the course of a problem. You may find it necessary to copy/paste relevant code into additional cells to accomplish this.\n",
        "\n",
        "- Feel free to use the lecture notes and other resources. But you\n",
        "must understand, write, and hand in your own answers. In addition, you must write and submit\n",
        "your own code in the programming part of the assignment (we may run your code).\n",
        "If you copy someone else homework solution, both of you may receive ZERO point. \n",
        "\n",
        "\n",
        "- Colab is preferred. However, if you use Anaconda, please download the .mat file locally and save it to the same folder as this homework file. "
      ],
      "metadata": {
        "id": "fai00CsquO-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Markov Chain (45pt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wL-8MIwOcx5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Q1.1 (15pt) \n",
        "Three different Markov Chains are defined by the following transition matrices: \n",
        "\\begin{align}\n",
        "\\bcm 1/3 & 1/3 & 1/3 \\\\\n",
        "     1/3 & 2/3 & 0 \\\\\n",
        "     1/3 & 0   & 2/3 \\ecm,\n",
        "\\bcm 1/3 & 1/3 & 0 & 1/3 \\\\ \n",
        "     1/4 & 1/4 & 1/4 & 1/4 \\\\\n",
        "     0 & 0 & 1 & 0 \\\\\n",
        "     1/2 & 0 & 0 & 1/2  \\ecm,\n",
        "\\bcm 1/2 & 0 & 0 & 0 & 1/2 \\\\\n",
        "     1/3 & 0 & 1/3 & 1/3 & 0\\\\\n",
        "     0 & 1/3 & 0 & 1/3 & 1/3 \\\\\n",
        "     0 & 0 & 0 & 1 & 0 \\\\\n",
        "     1 & 0 & 0 & 0 & 0\n",
        "\\ecm\n",
        "\\end{align}\n",
        "For each transition matrix, answer following questions:\n",
        "- Draw a directed graph. Is the Markov Chain irreducible? \n",
        "\n",
        "- Identify the communicating classes and classify them as periodic or aperiodic, transient or recurrent?\n",
        "\n",
        "- Does the Markov Chain has the unique invarant distribution? If yes, what is it?"
      ],
      "metadata": {
        "id": "LJq0GldpOlgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "m4VkpQs2goqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Q1.2 (10pt)\n",
        "Let $\\{X_n\\}$ be a Markov chain with transition matrix \n",
        "\\begin{align}\n",
        "\\m{P} = \\bcm 1-2p & 2p &0 \\\\\n",
        "         p & 1-2p  & p \\\\\n",
        "         0 & 2p & 1-2p\\ecm\n",
        "\\end{align}\n",
        "with $p\\in (0,1)$. Find $\\m{P}^n$, the invariant distribution $\\pi$ and the mean-recurrence times $\\mb{E}_i[T_i]$ for $i=1,2,3$."
      ],
      "metadata": {
        "id": "HdVDEAPiR8m8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "tY-x_jGCUHuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q1.3 (10pt)\n",
        "Prove the following statement: \n",
        "\n",
        "Recurrence is a communication class property, i.e. if $i↔j$ and $i$ is recurrent, then $j$ is\n",
        "recurrent.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "psx9t0j6UMHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "PR1JFsZBVj7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q1.4 (10pt)\n",
        "Prove the following two statements. \n",
        "\n",
        "- $P_i(N_i=\\infty)=1 ⇔ P_i(T_i<\\infty) =1. $\n",
        "\n",
        "- $P_i(T_i<\\infty) < 1 ⇔ P_i(N_i=\\infty)=0 ⇔ \\mb{E}_i[N_i]<\\infty$"
      ],
      "metadata": {
        "id": "XmLmV4TUgEHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "nyZ29BHEiWPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q2: Applications of Markov Chain (20pt)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Q2.1: Gambler's ruin problem (10pt)\n",
        "Player M has \\$1 and player N has \\$2. Each game gives the winner \\$1 from the other. As\n",
        "a better player, M wins 2/3 of the games. They play until one of them is bankrupt. What\n",
        "is the probability that M wins?\n"
      ],
      "metadata": {
        "id": "p4KeUFNJuRl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "aJCId-eEuuYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Q2.2: Dice Problem (10pt)\n",
        "Two players bet on roll(s) of the total of two standard six-face dice. Player A bets that a\n",
        "sum of 12 will occur first. Player B bets that two consecutive 7s will occur first. The\n",
        "players keep rolling the dice and record the sums until one player wins. What is the\n",
        "probability that A will win?\n"
      ],
      "metadata": {
        "id": "a-3P1K27vbae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "QbBaHmLjv3wz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q3: Markov Chain Simulation (35pt)\n",
        "\n",
        "**This problem together with Q1 and Q2 in HW1 can be used to present in showcase day as extra credits.**\n",
        "\n",
        "In the question, you are going to implement the time homogenous Markov Chain simuation. We would like to simulate the Markov chain for $T$ steps when given transition matrix and initial probability vector.\n",
        "\n",
        "## Q3.1: Implementation (20pt)\n",
        "The input parameter is ```status_num``` which is the number of states in Markov Chain. In the class, it has two parameters.\n",
        "\n",
        "- ```pi``` is the initial probability vector, with the size of ```status_num```. In particular, if ```pi=[1,0,0]```, it implies the initial state of the  is 0.  \n",
        "\n",
        "- ```P``` is the transition matrix of the Markov Chain, with the size of ```(status_num, status_num)```. Note each row should sums to 1. \n",
        "\n",
        "We talked about the algorithm to simulate Markov Chain. Here is the brief summary of the algorithm. \n",
        "\n",
        "- Sample the initial state $i_0$ that follows the multinormial distribution ```pi```. Set $X_0=i_0$ and $n=0$.\n",
        "\n",
        "- For $n< T$:\n",
        "   - Sample the state $i_{n+1}$ follows the multinormial distribution ```P[i_n]```, which is $i_n$-th row of the transition matrix $P$.\n",
        "   - Set $X_{n+1}=i_{n+1}$ and $n\\leftarrow n+1$. \n",
        "\n",
        "\n",
        "You may use ```numpy.random.Generator.multinomial``` function to draw samples from a multinomial distribution.    \n",
        "\n",
        "You will test your implemented class in the following script. Make certain that your implementation works correctly before moving on to the next part.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qMAQC0g5btGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovModel(object):\n",
        "    def __init__(self, status_num=None):\n",
        "      # Initial Probability Vector\n",
        "      self.pi = np.zeros(status_num)\n",
        "      # Probability Transition matrix\n",
        "      self.P = np.zeros(shape=(status_num, status_num))\n",
        "\n",
        "    def simulate(self, T):  \n",
        "      # TO DO \n"
      ],
      "metadata": {
        "id": "eR0fL5LNY6c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test case\n",
        "model = MarkovModel(status_num=3)\n",
        "model.P=np.asarray([\n",
        "    [1,0,0],\n",
        "    [1/3,1/3,1/3],\n",
        "    [0,0,1]\n",
        "])\n",
        "model.pi = np.asarray([1/3,1/3,1/3])\n",
        "T  = 10\n",
        "Traj = model.simulate(T)\n",
        "print(Traj)\n"
      ],
      "metadata": {
        "id": "gZmgbR6KoqtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q3.2: Use Monte Carlo simulatation to verify Q2.1 (15pt)\n",
        "Design a Monte Carlo Simulation experiment to verify your solution in Q2.1. Note \n",
        "- You need to specifiy the transition matrix and initial probability vector by yourself.  \n",
        "\n",
        "- You should run as many independent trajectories with the same initial probability vector and record which player wins at end. \n",
        "\n",
        "- You should set $T$ relatively large. If your simulated trajectory doesn't end with either player win, you should discard this trajectory. \n"
      ],
      "metadata": {
        "id": "aV6wHRX5rFbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code starts here"
      ],
      "metadata": {
        "id": "-ld23prTsAXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "5hseGxzjsC-h"
      }
    }
  ]
}