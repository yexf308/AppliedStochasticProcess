{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbm1nxns0Y4UuEIF+J5qx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStochasticProcess/blob/main/HW/HW4/560Sp23HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'networkx<2.7'"
      ],
      "metadata": {
        "id": "A_NwQ8AJlvzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c95cffa-4400-4e6f-ef04-08da49a9faa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting networkx<2.7\n",
            "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "Successfully installed networkx-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBBt9p6AW1-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a563bc37-8a83-42a3-e803-642b7fabf2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline \n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy import linalg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n",
        "# Homework 4\n",
        "## Homework guideline\n",
        "- The deadline is Apr 21st 10:30am. Submission after the deadline will not be graded. \n",
        "\n",
        "\n",
        "- Submit your work(your reasoning and your code) as a SINGLE .ipynb document. Please rename the document as _HW1_YOURNAME.ipynb_ (for example, _HW1_FELIX.ipynb_). You are responsible for checking that you have correctly submitted the correct document. If your code cannot run, you may receive NO point. \n",
        "\n",
        "- Please justify all short answers with a brief explanation. If you use latex command in the markdown, **2 points** bonus will be awarded.   \n",
        "\n",
        "\n",
        "\n",
        "- You only use the Python packages included in the following cell. You are not allowed to use other advanced package or modules unless you are permitted to. \n",
        "\n",
        "- In your final submission include the plots produced by the unedited code as presented below, as well as any additional plots produced after editing the code during the course of a problem. You may find it necessary to copy/paste relevant code into additional cells to accomplish this.\n",
        "\n",
        "- Feel free to use the lecture notes and other resources. But you\n",
        "must understand, write, and hand in your own answers. In addition, you must write and submit\n",
        "your own code in the programming part of the assignment (we may run your code).\n",
        "If you copy someone else homework solution, both of you may receive ZERO point. \n",
        "\n",
        "\n",
        "- Colab is preferred. However, if you use Anaconda, please download the .mat file locally and save it to the same folder as this homework file. \n",
        "\n"
      ],
      "metadata": {
        "id": "GtKXZI05siLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Q1: Implementing PageRank (20pt)\n",
        "\n",
        "**This problem can be used to present in showcase day as extra credits.**\n",
        "\n",
        "First of all, we authenticate a Google Drive client to download the dataset we will be processing in this Colab.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ],
      "metadata": {
        "id": "LLKnt8zGlj-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id='1EoolSK32_U74I4FeLox88iuUB_SUUYsI'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('web-Stanford.txt')"
      ],
      "metadata": {
        "id": "w1-2oEFJln1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n",
        "\n",
        "For this Colab we will be using [NetworkX](https://networkx.github.io), a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
        "\n",
        "If you want to explore NetworkX more, consider following [this tutorial](https://networkx.org/documentation/stable/tutorial.html).\n",
        "\n",
        "The dataset we will analyze is a snapshot of the Web Graph centered around [stanford.edu](https://stanford.edu), collected in 2002. Nodes represent pages from Stanford University (stanford.edu) and directed edges represent hyperlinks between them. [[More Info]](http://snap.stanford.edu/data/web-Stanford.html). \n",
        "\n",
        "The dataset is massive so brute force method is not possible. "
      ],
      "metadata": {
        "id": "qePXWLXkls-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the graph as directed graph\n",
        "import networkx as nx\n",
        "G = nx.read_edgelist('web-Stanford.txt', create_using=nx.MultiDiGraph )\n",
        "print(nx.info(G))"
      ],
      "metadata": {
        "id": "TcOtOsOvl108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b07c00-45ec-402f-960a-0ce165187912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiDiGraph with 281903 nodes and 2312497 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = nx.adjacency_matrix(G)\n",
        "print(W.shape)"
      ],
      "metadata": {
        "id": "IISoWVnBl4aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71383970-ae67-4b19-d2e3-a0eff1bf609d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(281903, 281903)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = sum(W,axis=1)\n",
        "np.asarray(arr).reshape(-1)\n",
        "arr[arr==0].shape"
      ],
      "metadata": {
        "id": "yczlqxH5l6Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2b8b5e-5221-41fb-cbda-d97a3bc5ad37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 172)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nodes of G in the following order \n",
        "# nodes are not in the order of '1', '2', '3', ...\n",
        "print(G.nodes)"
      ],
      "metadata": {
        "id": "C-twJkHCl70h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm of Pagerank\n",
        "The markov matrix $P_\\alpha=\\alpha D^{-1}W +(1-\\alpha) E$, where $E=\\frac{1}{N}\\mathbb{1}\\mathbb{1}^\\top$. In pagerank, $\\alpha$ is set as 0.85. \n",
        " We will implement power method to caclulate the stationary distribution. \n",
        "\n",
        "- Initialize the row vector: $\\mathbf{r}^{(0)}=\\frac{1}{N}\\mathbb{1}$.\n",
        "\n",
        "- Iterate for $i$ from 1 to $k$, $\\mathbf{r}^{(i+1)}=\\mathbf{r}^{(i)}P_\\alpha$. $P_\\alpha$ is NOT sparse and you should not explicitly write up $P_\\alpha$, instead you should implement the sparse multiplcation. \n",
        "\n",
        "- Please set up your own stopping criteria and stop the iteration if needed.   "
      ],
      "metadata": {
        "id": "n8zTW_kVl9nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code starts here"
      ],
      "metadata": {
        "id": "jsgT0W-wl_x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Q2: Gaussian Mixture Models (25pt)\n",
        "\n"
      ],
      "metadata": {
        "id": "HoNb_1cN2HvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Q2.1. Construct a function to calculate log likelihood (5pt)\n",
        "Say you have applied EM algorithm in the Gaussian Mixture model and have found the optimal parameter $\\hat{\\mm\\theta}=\\{\\hat\\pi_k, \\hat{\\mm\\mu}_k, \\hat{\\mm\\Sigma}_k\\}_{k=1}^K$. Construct a function to calculate the log likelihood $\\ell(\\theta)$"
      ],
      "metadata": {
        "id": "H_yYNp_42J_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Q2.1 your code starts here\n",
        " def log_likelihood(X,K,Pi_opt,Mu_opt, Sigma_opt):\n",
        "   return"
      ],
      "metadata": {
        "id": "-XoZWXOt2Oiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Q2.2 BIC (10pt)\n",
        "\n",
        "In Gaussian mixture models, one question is how to choose the number of the cluster $K$. We will use slightly more complicated criterion, Bayesian information criterion (BIC). \n",
        "\n",
        "Remember the definition of BIC is \n",
        "\\begin{align}\n",
        "\\mr{BIC}(K) = \\log p(D|\\hat{\\mm\\theta})-\\frac{d_K}{2}\\log(N)\n",
        "\\end{align}\n",
        "The first term is the log-likelihood $\\log\\ell(\\hat{\\mm\\theta})$, $d_K$ is the number of free parameters in the model and $N$ is the number of samples. Overall, the higher BIC value, the better of the model. \n",
        "\n",
        "What is $d_K$ in GMM for $K$ clusters? \n",
        "Please construct a function to calculate the Bayesian information criterion. \n"
      ],
      "metadata": {
        "id": "WPpRhuYfxa57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "UU609GjPyHs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.2  your code starts here\n",
        " def BIC(K,d,N,log_ell_hat):\n",
        "   return"
      ],
      "metadata": {
        "id": "znB3d1pR0qk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q2.3. Testing with the synthetic dataset (10pt)\n",
        "Performing Gaussian mixture models over the loop for an increasing number of $K$ from 2 to 6. Note for each $K$, you should run your GMM several times with differnt random initial conditions, to make sure the parameter is not trapped in the local optimum. Plot BIC value vs. the number of the cluster $K$. From the plot, please comment what is the optimal $K$. \n",
        "\n",
        "(It is always a good habit to start your code for some special $K$, say $K=3$. Make sure your code produces the correct result first, then put it into the loop with different $K$. )"
      ],
      "metadata": {
        "id": "QBqcCZt90t2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/2DGaussianMixture.csv?raw=true -O 2DGaussianMixture.csv\n"
      ],
      "metadata": {
        "id": "_WO0ob3O0yMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.genfromtxt(\"2DGaussianMixture.csv\", delimiter=\",\")\n",
        "X = X[1:]\n",
        "X = X[:,1:]\n",
        "plt.scatter(X[:,0],X[:,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jooicTgX00AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.3 Your code starts here"
      ],
      "metadata": {
        "id": "jDnJ1lQl02gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Q3: Boxes and Balls Model (30pt)\n",
        "If we have three boxes and each box contains red and white balls. \n",
        "- In box 1, it has 5 red balls and 5 white balls.\n",
        "\n",
        "- In box 2, it has 4 red balls and 6 white balls.\n",
        "\n",
        "- In box 3, it has 7 red balls and 3 white balls.\n",
        "\n",
        "\n",
        "We will pick balls in the following way and record the color of picked balls:\n",
        "\n",
        "1. Initially, we randomly choose a box with the probability $\\pi=(0.2, 0.4, 0.4)$. Then we pick a ball, record the color and put the ball back to the same box. \n",
        "\n",
        "2. Based on the current box we choosen, we will choose the next box. So this process follows a Markov Chain with the transition probability matrix \n",
        "\\begin{align}\n",
        "M=\\bcm 0.5 & 0.2 & 0.3 \\\\\n",
        "       0.3 & 0.5 & 0.2 \\\\\n",
        "       0.2 & 0.3 & 0.5\\ecm\n",
        "\\end{align}\n",
        "\n",
        "3. After we choose the next box, we pick a ball, record the color and put the ball back to the same box.\n",
        "\n",
        "4. Repeat Step 2 and Step 3 three times. The observed sequence of the color of picked balls is \n",
        "\\begin{align}\n",
        "O=\\{\\text{red},\\text{white},\\text{red},\\text{white} \\}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "## Q3.1: Backward Algorithm (15pt)\n",
        "Use backward algorithm to calculate $p(O|\\mm\\theta)$. You may use python code to help your calculation."
      ],
      "metadata": {
        "id": "79HAfKu2n583"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "sidW1od4t0h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.1 Your code starts here"
      ],
      "metadata": {
        "id": "K-MaLJQEt1en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3.2: Viterbi algorithm (15pt)\n",
        "Use Viterbi algorithm to find the most likely sequence of hidden states, i.e., the sequence of boxes chosen.  You may use python code to help your calculation."
      ],
      "metadata": {
        "id": "YbhIvztuu7KR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "4waUeJRIva7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.2 Your code starts here"
      ],
      "metadata": {
        "id": "hA0Vh5v4vY42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Q4: Theory in Hidden Markov Model (25pt)\n",
        "Consider the hidden Markov model specified by the following graph\n",
        "<img src=\"https://github.com/yexf308/AppliedStochasticProcess/blob/main/HW/HW4/DAG.png?raw=true\" width=\"800\" />\n",
        "\n",
        "## Q4.1: Predictive distributions (10pt)\n",
        "For the hidden Markov model\n",
        "\\begin{align}\n",
        "p(h_{1:n}, v_{1:n})= p(v_1|h_1)p(h_1)\\Pi_{i=2}^n p(v_i|h_i)p(h_i|h_{i-1})\n",
        "\\end{align}\n",
        "assume you have observations for $v_i, i=1, \\dots,u<n$.\n",
        "\n",
        "- Compute $p(h_t|v_{1:u})$ for $u<t\\le n$.  For the sake of concreteness, you may consider the case $n=6, u=2, t=4$.\n",
        "\n",
        "- Compute $p(v_t|v_{1:u})$ for $u<t\\le n$. For the sake of concreteness, you may consider the case $n=6, u=2, t=4$.\n",
        "\n",
        "Please express your results using transition probability and emission probability."
      ],
      "metadata": {
        "id": "DJn57kPQBNg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "3ZYZ9TdpJ0n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Q4.2: Forward filtering backward sampling\n",
        "We assume that have already run the alpha-recursion (filtering) and can compute $p(h_t|v_{1:t})$\n",
        "for all $t$. The goal is now to generate samples $p(h_1,\\dots h_n|v_{1:n}),$ i.e. entire trajectories $(h_1,\\dots, h_n)$ from the posterior. Note that this is not the same as sampling from the $n$ filtering distributions $p(h_t|v_{1:t})$. Moreover, compared to the Viterbi algorithm, the sampling\n",
        "approach generates samples from the full posterior rather than just returning the most probable state and its corresponding probability.\n",
        "\n",
        "### Q4.2.1: (10pt)\n",
        "Since $p(h_1,\\dots, h_n|v_{1:n})$ is a first-order Markov chain, it suffices to determine $p(h_{t-1}|h_t; v_{1:n})$,\n",
        "the probability mass function for $h_{t-1}$ given $h_t$ and all the data $v_{1:n}$. Show that \n",
        "\\begin{align}\n",
        "p(h_{t-1}, h_t| v_{1:n}) \\propto \\alpha(h_{t-1})\\beta(h_t)p(h_t| h_{t-1})p(v_t|h_t)\n",
        "\\end{align}\n"
      ],
      "metadata": {
        "id": "DvnOgnOeNcZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "1_G3a_BvJchT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4.2.2: (5pt)\n",
        "Show that \n",
        "\\begin{align}\n",
        "p(h_{t-1}| h_t, v_{1:n}) =\\frac{\\alpha(h_{t-1})}{\\alpha(h_t)}p(h_t| h_{t-1})p(v_t|h_t)\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "TkQj5u_pJeXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "Bd-9RxkomQAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** \n",
        "We thus obtain the following algorithm to generate samples from $p(h_1, \\dots, h_n | v_{1:n})$:\n",
        "\n",
        "- Run the filtering to determine all $\\alpha(h_t)$ forward in time for $t=1, \\dots, n$.\n",
        "\n",
        "- Sample $h_n$ from $p(h_n|v_{1:n})\\propto\\alpha(h_n)$.\n",
        "\n",
        "-  Go backwards in time using\n",
        "\\begin{align}\n",
        "p(h_{t-1}| h_t, v_{1:n}) =\\frac{\\alpha(h_{t-1})}{\\alpha(h_t)}p(h_t| h_{t-1})p(v_t|h_t)\n",
        "\\end{align}\n",
        "to generate samples $h_{t-1}| h_t, v_{1:n}$ for $t=n,\\dots, 2$.\n",
        "\n",
        "This algorithm is known as forward filtering backward sampling (FFBS)."
      ],
      "metadata": {
        "id": "RsLuDcW2XawP"
      }
    }
  ]
}